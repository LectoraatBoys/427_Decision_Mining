distilbert.embeddings.word_embeddings.weight torch.Size([30522, 768])
distilbert.embeddings.position_embeddings.weight torch.Size([512, 768])
distilbert.embeddings.LayerNorm.weight torch.Size([768])
distilbert.embeddings.LayerNorm.bias torch.Size([768])
distilbert.transformer.layer.0.attention.q_lin.weight torch.Size([768, 768])
distilbert.transformer.layer.0.attention.q_lin.bias torch.Size([768])
distilbert.transformer.layer.0.attention.k_lin.weight torch.Size([768, 768])
distilbert.transformer.layer.0.attention.k_lin.bias torch.Size([768])
distilbert.transformer.layer.0.attention.v_lin.weight torch.Size([768, 768])
distilbert.transformer.layer.0.attention.v_lin.bias torch.Size([768])
distilbert.transformer.layer.0.attention.out_lin.weight torch.Size([768, 768])
distilbert.transformer.layer.0.attention.out_lin.bias torch.Size([768])
distilbert.transformer.layer.0.sa_layer_norm.weight torch.Size([768])
distilbert.transformer.layer.0.sa_layer_norm.bias torch.Size([768])
distilbert.transformer.layer.0.ffn.lin1.weight torch.Size([3072, 768])
distilbert.transformer.layer.0.ffn.lin1.bias torch.Size([3072])
distilbert.transformer.layer.0.ffn.lin2.weight torch.Size([768, 3072])
distilbert.transformer.layer.0.ffn.lin2.bias torch.Size([768])
distilbert.transformer.layer.0.output_layer_norm.weight torch.Size([768])
distilbert.transformer.layer.0.output_layer_norm.bias torch.Size([768])
distilbert.transformer.layer.1.attention.q_lin.weight torch.Size([768, 768])
distilbert.transformer.layer.1.attention.q_lin.bias torch.Size([768])
distilbert.transformer.layer.1.attention.k_lin.weight torch.Size([768, 768])
distilbert.transformer.layer.1.attention.k_lin.bias torch.Size([768])
distilbert.transformer.layer.1.attention.v_lin.weight torch.Size([768, 768])
distilbert.transformer.layer.1.attention.v_lin.bias torch.Size([768])
distilbert.transformer.layer.1.attention.out_lin.weight torch.Size([768, 768])
distilbert.transformer.layer.1.attention.out_lin.bias torch.Size([768])
distilbert.transformer.layer.1.sa_layer_norm.weight torch.Size([768])
distilbert.transformer.layer.1.sa_layer_norm.bias torch.Size([768])
distilbert.transformer.layer.1.ffn.lin1.weight torch.Size([3072, 768])
distilbert.transformer.layer.1.ffn.lin1.bias torch.Size([3072])
distilbert.transformer.layer.1.ffn.lin2.weight torch.Size([768, 3072])
distilbert.transformer.layer.1.ffn.lin2.bias torch.Size([768])
distilbert.transformer.layer.1.output_layer_norm.weight torch.Size([768])
distilbert.transformer.layer.1.output_layer_norm.bias torch.Size([768])
distilbert.transformer.layer.2.attention.q_lin.weight torch.Size([768, 768])
distilbert.transformer.layer.2.attention.q_lin.bias torch.Size([768])
distilbert.transformer.layer.2.attention.k_lin.weight torch.Size([768, 768])
distilbert.transformer.layer.2.attention.k_lin.bias torch.Size([768])
distilbert.transformer.layer.2.attention.v_lin.weight torch.Size([768, 768])
distilbert.transformer.layer.2.attention.v_lin.bias torch.Size([768])
distilbert.transformer.layer.2.attention.out_lin.weight torch.Size([768, 768])
distilbert.transformer.layer.2.attention.out_lin.bias torch.Size([768])
distilbert.transformer.layer.2.sa_layer_norm.weight torch.Size([768])
distilbert.transformer.layer.2.sa_layer_norm.bias torch.Size([768])
distilbert.transformer.layer.2.ffn.lin1.weight torch.Size([3072, 768])
distilbert.transformer.layer.2.ffn.lin1.bias torch.Size([3072])
distilbert.transformer.layer.2.ffn.lin2.weight torch.Size([768, 3072])
distilbert.transformer.layer.2.ffn.lin2.bias torch.Size([768])
distilbert.transformer.layer.2.output_layer_norm.weight torch.Size([768])
distilbert.transformer.layer.2.output_layer_norm.bias torch.Size([768])
distilbert.transformer.layer.3.attention.q_lin.weight torch.Size([768, 768])
distilbert.transformer.layer.3.attention.q_lin.bias torch.Size([768])
distilbert.transformer.layer.3.attention.k_lin.weight torch.Size([768, 768])
distilbert.transformer.layer.3.attention.k_lin.bias torch.Size([768])
distilbert.transformer.layer.3.attention.v_lin.weight torch.Size([768, 768])
distilbert.transformer.layer.3.attention.v_lin.bias torch.Size([768])
distilbert.transformer.layer.3.attention.out_lin.weight torch.Size([768, 768])
distilbert.transformer.layer.3.attention.out_lin.bias torch.Size([768])
distilbert.transformer.layer.3.sa_layer_norm.weight torch.Size([768])
distilbert.transformer.layer.3.sa_layer_norm.bias torch.Size([768])
distilbert.transformer.layer.3.ffn.lin1.weight torch.Size([3072, 768])
distilbert.transformer.layer.3.ffn.lin1.bias torch.Size([3072])
distilbert.transformer.layer.3.ffn.lin2.weight torch.Size([768, 3072])
distilbert.transformer.layer.3.ffn.lin2.bias torch.Size([768])
distilbert.transformer.layer.3.output_layer_norm.weight torch.Size([768])
distilbert.transformer.layer.3.output_layer_norm.bias torch.Size([768])
distilbert.transformer.layer.4.attention.q_lin.weight torch.Size([768, 768])
distilbert.transformer.layer.4.attention.q_lin.bias torch.Size([768])
distilbert.transformer.layer.4.attention.k_lin.weight torch.Size([768, 768])
distilbert.transformer.layer.4.attention.k_lin.bias torch.Size([768])
distilbert.transformer.layer.4.attention.v_lin.weight torch.Size([768, 768])
distilbert.transformer.layer.4.attention.v_lin.bias torch.Size([768])
distilbert.transformer.layer.4.attention.out_lin.weight torch.Size([768, 768])
distilbert.transformer.layer.4.attention.out_lin.bias torch.Size([768])
distilbert.transformer.layer.4.sa_layer_norm.weight torch.Size([768])
distilbert.transformer.layer.4.sa_layer_norm.bias torch.Size([768])
distilbert.transformer.layer.4.ffn.lin1.weight torch.Size([3072, 768])
distilbert.transformer.layer.4.ffn.lin1.bias torch.Size([3072])
distilbert.transformer.layer.4.ffn.lin2.weight torch.Size([768, 3072])
distilbert.transformer.layer.4.ffn.lin2.bias torch.Size([768])
distilbert.transformer.layer.4.output_layer_norm.weight torch.Size([768])
distilbert.transformer.layer.4.output_layer_norm.bias torch.Size([768])
distilbert.transformer.layer.5.attention.q_lin.weight torch.Size([768, 768])
distilbert.transformer.layer.5.attention.q_lin.bias torch.Size([768])
distilbert.transformer.layer.5.attention.k_lin.weight torch.Size([768, 768])
distilbert.transformer.layer.5.attention.k_lin.bias torch.Size([768])
distilbert.transformer.layer.5.attention.v_lin.weight torch.Size([768, 768])
distilbert.transformer.layer.5.attention.v_lin.bias torch.Size([768])
distilbert.transformer.layer.5.attention.out_lin.weight torch.Size([768, 768])
distilbert.transformer.layer.5.attention.out_lin.bias torch.Size([768])
distilbert.transformer.layer.5.sa_layer_norm.weight torch.Size([768])
distilbert.transformer.layer.5.sa_layer_norm.bias torch.Size([768])
distilbert.transformer.layer.5.ffn.lin1.weight torch.Size([3072, 768])
distilbert.transformer.layer.5.ffn.lin1.bias torch.Size([3072])
distilbert.transformer.layer.5.ffn.lin2.weight torch.Size([768, 3072])
distilbert.transformer.layer.5.ffn.lin2.bias torch.Size([768])
distilbert.transformer.layer.5.output_layer_norm.weight torch.Size([768])
distilbert.transformer.layer.5.output_layer_norm.bias torch.Size([768])
pre_classifier.weight torch.Size([768, 768])
pre_classifier.bias torch.Size([768])
classifier.weight torch.Size([2, 768])
classifier.bias torch.Size([2])
